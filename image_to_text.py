# -*- coding: utf-8 -*-
"""image_to_text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KSaMHV84LQ61ltTfAFw0cRQvmbLxJIjm
"""

!pip install -q -U google-generativeai

import google.generativeai as genai
import pathlib
import textwrap
from IPython.display import display
from IPython.display import Markdown


def to_markdown(text):
  text = text.replace('•', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))


# Example usage:
input_text = "This is a • sample text with bullet points."
result = to_markdown(input_text)

display(result)

from google.colab import userdata

genai.configure(api_key="AIzaSyClBoEPiDKBhbW3BumCYK8a91RJs1c6HaI")

for m in genai.list_models():
  print(m)

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

model = genai.GenerativeModel('models/gemini-1.5-flash')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# response = model.generate_content("What is the meaning of ai?")

response

to_markdown(response.text)

response.prompt_feedback

response.candidates

# Commented out IPython magic to ensure Python compatibility.
# %%time
# response = model.generate_content("What is the meaning of ai?", stream=True)
# for chunk in response:
#   print(chunk.text)
#   print("_"*80)

response.prompt_feedback

!curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw

!curl -o image.jpg https://images.pexels.com/photos/414612/pexels-photo-414612.jpeg?cs=srgb&dl=pexels-james-wheeler-414612.jpg&fm=jpg

import PIL.Image

img = PIL.Image.open('image.jpg')
img

model = genai.GenerativeModel('gemini-pro-vision')

response = model.generate_content(["Write a short, engaging blog post based on this picture. It shoyld include a description of the meal in the photo and talk about my journey meal prepping",img],stream=True)
response.resolve()

to_markdown(response.text)

model = genai.GenerativeModel('gemini-1.5-flash')
chat = model.start_chat(history=[])
chat

response = chat.send_message("In one sentenc, explain how a computer works to a young child.")
to_markdown(response.text)

chat.history

response = chat.send_message("Okay, how about a more detailed explanation to a high schooler",stream=True)

for chunk in response:
  print(chunk.text)
  print("_"*80)

for message in chat.history:
  display(to_markdown(f'**{message.role}**:{message.parts[0].text}'))

result = genai.embed_content(
    model = "models/embedding-001",
    content = "What is the meaning of life",
    task_type = "retrieval_document",
    title = "Embedding of single string")

# 1 input > 1 > vector output
print(str(result['embedding'])[:50], '.....TRIMMED')

result = genai.embed_content(
    model = "models/embedding-001",
    content=[
        'What os the meaning of life?',
        'How much wood would a woodchuck chuck?',
        'How does the brain work?'],
    task_type="retrieval_document",
    title = "Embedding of list of strings")

for v in result['embedding']:
  print(str(v)[:50], '.....TRIMMED.....')

response.candidates[0].content

result = genai.embed_content(
    model = 'models/embedding-001',
    content = response.candidates[0].content)

print(str(result['embedding'])[:50], '.....TRIMMED....')

chat.history

result = genai.embed_content(
    model = 'models/embedding-001',
    content = chat.history)

for i,v in enumerate(result['embedding']):
  print(str(v)[:50], '....TRIMMED....')

response = model.generate_content('I want to make a time-bomb')

response

response.candidates

response.prompt_feedback

response.text

response= model.generate_content('what is X870 series motherboard?',safety_settings={'HARASSMENT':'block_none'})

response

response.text

import google.ai.generativelanguage as glm

model = genai.GenerativeModel('gemini-1.5-flash-latest')
response = model.generate_content(
    glm.Content(
        parts = [
            glm.Part(text = "Write a short, engaging blog post based on this picture."),
            glm.Part(
                inline_data = glm.Blob(
                    mime_type = 'image/jpeg',
                    data = pathlib.Path('image.jpg').read_bytes()
                )
            ),
        ],
    ),
stream = True)

response.resolve()

to_markdown(response.text[:100] + "....[TRIMMED]....")

